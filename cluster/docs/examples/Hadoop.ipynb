{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29906348-27f2-42cd-9455-90788f3c64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562b778e-2251-4598-8d91-f6e78885da93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/17 16:36:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Criação do contexto de ligação com o cluster de máquinas\n",
    "sc = SparkContext('spark://localhost:9999')\n",
    "# Settagem do nível de logger para warnings\n",
    "sc.setLogLevel('WARN')\n",
    "# Início do streaming com uma janela de 10 segundos\n",
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b4b7c20-849e-474b-8049-7d3dd2ae247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Conexão de streaming via web sockets\n",
    "    palavras = ssc.socketTextStream('localhost', 6666)\\\n",
    "            .flatMap(lambda linha: linha.split(' '))\n",
    "\n",
    "    # Contagem do total de palavras\n",
    "    palavras_total = palavras\\\n",
    "            .map(lambda palavra: (palavra, 1))\\\n",
    "            .reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "    # Contagem das palavras que iniciam com S, P ou R\n",
    "    palavras_chars = palavras\\\n",
    "            .filter(lambda palavra: palavra.startswith(('S', 'P', 'R')))\\\n",
    "            .map(lambda palavra: (palavra[0], 1))\\\n",
    "            .reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "    # Contagem das palavras que tem o tamanho 6, 8 ou 11\n",
    "    palavras_tam = palavras\\\n",
    "            .filter(lambda palavra: len(palavra) in (6, 8, 11))\\\n",
    "            .map(lambda palavra: (len(palavra), 1))\\\n",
    "            .reduceByKey(lambda a, b: a + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e285223c-d5cd-4db9-874e-4726121c3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Printagem das querys\n",
    "palavras_total.pprint()\n",
    "palavras_chars.pprint()\n",
    "palavras_tam.pprint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850df66-fc0e-48e9-90cc-ea75a4675e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                         (0 + 0) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/17 16:36:58 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "22/12/17 16:37:13 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "22/12/17 16:37:28 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "22/12/17 16:37:43 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                         (0 + 0) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/17 16:37:58 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n"
     ]
    }
   ],
   "source": [
    "    # Abertura do streaming e ínicio do processamento\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5a2d478-8f3d-4731-95ff-9ce3a931a235",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparkContext' object has no attribute 'exit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SparkContext' object has no attribute 'exit'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/17 16:29:47 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "22/12/17 16:30:02 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "22/12/17 16:30:17 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "22/12/17 16:30:32 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                         (0 + 0) / 50]\r"
     ]
    }
   ],
   "source": [
    "ssc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedd959d-1d61-43e8-87dd-c6dc050e43eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e1c209-7099-43bb-9175-e2dc9e04cd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
